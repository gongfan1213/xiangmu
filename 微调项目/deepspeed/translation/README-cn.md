<!---
Copyright 2020 The HuggingFace Team. All rights reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
-->

## æœºå™¨ç¿»è¯‘

æœ¬ç›®å½•åŒ…å«åœ¨ç¿»è¯‘ä»»åŠ¡ä¸Šå¾®è°ƒå’Œè¯„ä¼° transformers æ¨¡å‹çš„ç¤ºä¾‹ã€‚
å¦‚æœ‰é—®é¢˜æˆ–æ„å¤–è¡Œä¸ºï¼Œè¯·æ ‡è®° @patil-suraj æˆ–å‘é€ PRï¼
å¯¹äºå·²å¼ƒç”¨çš„ `bertabs` è¯´æ˜ï¼Œè¯·å‚é˜… [`bertabs/README.md`](https://github.com/huggingface/transformers/blob/main/examples/research_projects/bertabs/README.md)ã€‚
å¯¹äºæ—§çš„ `finetune_trainer.py` å’Œç›¸å…³å·¥å…·ï¼Œè¯·å‚é˜… [`examples/legacy/seq2seq`](https://github.com/huggingface/transformers/blob/main/examples/legacy/seq2seq)ã€‚

### æ”¯æŒçš„æ¶æ„

- `BartForConditionalGeneration`
- `FSMTForConditionalGeneration`ï¼ˆä»…ç¿»è¯‘ï¼‰
- `MBartForConditionalGeneration`
- `MarianMTModel`
- `PegasusForConditionalGeneration`
- `T5ForConditionalGeneration`
- `MT5ForConditionalGeneration`

`run_translation.py` æ˜¯ä¸€ä¸ªè½»é‡çº§ç¤ºä¾‹ï¼Œå±•ç¤ºå¦‚ä½•ä» [ğŸ¤— Datasets](https://github.com/huggingface/datasets) åº“ä¸‹è½½å’Œé¢„å¤„ç†æ•°æ®é›†ï¼Œæˆ–ä½¿ç”¨æ‚¨è‡ªå·±çš„æ–‡ä»¶ï¼ˆjsonlines æˆ– csvï¼‰ï¼Œç„¶ååœ¨ä¸Šè¿°æ¶æ„ä¹‹ä¸€ä¸Šè¿›è¡Œå¾®è°ƒã€‚

å¯¹äº `jsonlines` æ ¼å¼çš„è‡ªå®šä¹‰æ•°æ®é›†ï¼Œè¯·å‚é˜…ï¼šhttps://huggingface.co/docs/datasets/loading_datasets#json-files
æ‚¨ä¹Ÿå¯ä»¥åœ¨ä¸‹é¢æ‰¾åˆ°è¿™äº›ç¤ºä¾‹ã€‚

## ä½¿ç”¨ Trainer

ä»¥ä¸‹æ˜¯ä½¿ç”¨ MarianMT æ¨¡å‹è¿›è¡Œç¿»è¯‘å¾®è°ƒçš„ç¤ºä¾‹ï¼š

```bash
python examples/pytorch/translation/run_translation.py \
    --model_name_or_path Helsinki-NLP/opus-mt-en-ro \
    --do_train \
    --do_eval \
    --source_lang en \
    --target_lang ro \
    --dataset_name wmt16 \
    --dataset_config_name ro-en \
    --output_dir /tmp/tst-translation \
    --per_device_train_batch_size=4 \
    --per_device_eval_batch_size=4 \
    --overwrite_output_dir \
    --predict_with_generate
```

MBart å’Œä¸€äº› T5 æ¨¡å‹éœ€è¦ç‰¹æ®Šå¤„ç†ã€‚

T5 æ¨¡å‹ `t5-small`ã€`t5-base`ã€`t5-large`ã€`t5-3b` å’Œ `t5-11b` å¿…é¡»ä½¿ç”¨é¢å¤–çš„å‚æ•°ï¼š`--source_prefix "translate {source_lang} to {target_lang}"`ã€‚ä¾‹å¦‚ï¼š

```bash
python examples/pytorch/translation/run_translation.py \
    --model_name_or_path t5-small \
    --do_train \
    --do_eval \
    --source_lang en \
    --target_lang ro \
    --source_prefix "translate English to Romanian: " \
    --dataset_name wmt16 \
    --dataset_config_name ro-en \
    --output_dir /tmp/tst-translation \
    --per_device_train_batch_size=4 \
    --per_device_eval_batch_size=4 \
    --overwrite_output_dir \
    --predict_with_generate
```

å¦‚æœæ‚¨å¾—åˆ°å¾ˆå·®çš„ BLEU åˆ†æ•°ï¼Œè¯·ç¡®ä¿æ‚¨æ²¡æœ‰å¿˜è®°ä½¿ç”¨ `--source_prefix` å‚æ•°ã€‚

å¯¹äºä¸Šè¿° T5 æ¨¡å‹ç»„ï¼Œé‡è¦çš„æ˜¯è¦è®°ä½ï¼Œå¦‚æœæ‚¨åˆ‡æ¢åˆ°ä¸åŒçš„è¯­è¨€å¯¹ï¼Œè¯·ç¡®ä¿åœ¨æ‰€æœ‰ 3 ä¸ªç‰¹å®šäºè¯­è¨€çš„å‘½ä»¤è¡Œå‚æ•°ä¸­è°ƒæ•´æºå’Œç›®æ ‡å€¼ï¼š`--source_lang`ã€`--target_lang` å’Œ `--source_prefix`ã€‚

MBart æ¨¡å‹éœ€è¦ `--source_lang` å’Œ `--target_lang` å€¼çš„ä¸åŒæ ¼å¼ï¼Œä¾‹å¦‚ï¼Œä¸æ˜¯ `en` è€Œæ˜¯ `en_XX`ï¼Œå¯¹äº `ro` æ˜¯ `ro_RO`ã€‚å®Œæ•´çš„ MBart è¯­è¨€ä»£ç è§„èŒƒå¯ä»¥åœ¨[è¿™é‡Œ](https://huggingface.co/facebook/mbart-large-cc25)æ‰¾åˆ°ã€‚ä¾‹å¦‚ï¼š

```bash
python examples/pytorch/translation/run_translation.py \
    --model_name_or_path facebook/mbart-large-en-ro  \
    --do_train \
    --do_eval \
    --dataset_name wmt16 \
    --dataset_config_name ro-en \
    --source_lang en_XX \
    --target_lang ro_RO \
    --output_dir /tmp/tst-translation \
    --per_device_train_batch_size=4 \
    --per_device_eval_batch_size=4 \
    --overwrite_output_dir \
    --predict_with_generate
 ```

ä»¥ä¸‹æ˜¯å¦‚ä½•åœ¨æ‚¨è‡ªå·±çš„æ–‡ä»¶ä¸Šä½¿ç”¨ç¿»è¯‘å¾®è°ƒï¼Œåœ¨è°ƒæ•´å‚æ•° `--train_file`ã€`--validation_file` çš„å€¼ä»¥åŒ¹é…æ‚¨çš„è®¾ç½®åï¼š

```bash
python examples/pytorch/translation/run_translation.py \
    --model_name_or_path t5-small \
    --do_train \
    --do_eval \
    --source_lang en \
    --target_lang ro \
    --source_prefix "translate English to Romanian: " \
    --dataset_name wmt16 \
    --dataset_config_name ro-en \
    --train_file path_to_jsonlines_file \
    --validation_file path_to_jsonlines_file \
    --output_dir /tmp/tst-translation \
    --per_device_train_batch_size=4 \
    --per_device_eval_batch_size=4 \
    --overwrite_output_dir \
    --predict_with_generate
```

ç¿»è¯‘ä»»åŠ¡ä»…æ”¯æŒè‡ªå®šä¹‰ JSONLINES æ–‡ä»¶ï¼Œæ¯è¡Œéƒ½æ˜¯ä¸€ä¸ªå­—å…¸ï¼Œå…¶ä¸­é”®ä¸º `"translation"`ï¼Œå…¶å€¼æ˜¯å¦ä¸€ä¸ªå­—å…¸ï¼Œå…¶é”®æ˜¯è¯­è¨€å¯¹ã€‚ä¾‹å¦‚ï¼š

```json
{ "translation": { "en": "Others have dismissed him as a joke.", "ro": "AlÈ›ii l-au numit o glumÄƒ." } }
{ "translation": { "en": "And some are holding out for an implosion.", "ro": "Iar alÈ›ii aÈ™teaptÄƒ implozia." } }
```
è¿™é‡Œçš„è¯­è¨€æ˜¯ç½—é©¬å°¼äºšè¯­ï¼ˆ`ro`ï¼‰å’Œè‹±è¯­ï¼ˆ`en`ï¼‰ã€‚

å¦‚æœæ‚¨æƒ³ä½¿ç”¨å¯¼è‡´é«˜ BLEU åˆ†æ•°çš„é¢„å¤„ç†æ•°æ®é›†ï¼Œä½†å¯¹äº `en-de` è¯­è¨€å¯¹ï¼Œæ‚¨å¯ä»¥ä½¿ç”¨ `--dataset_name stas/wmt14-en-de-pre-processed`ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š

```bash
python examples/pytorch/translation/run_translation.py \
    --model_name_or_path t5-small \
    --do_train \
    --do_eval \
    --source_lang en \
    --target_lang de \
    --source_prefix "translate English to German: " \
    --dataset_name stas/wmt14-en-de-pre-processed \
    --output_dir /tmp/tst-translation \
    --per_device_train_batch_size=4 \
    --per_device_eval_batch_size=4 \
    --overwrite_output_dir \
    --predict_with_generate
 ```

## ä½¿ç”¨ Accelerate

åŸºäºè„šæœ¬ [`run_translation_no_trainer.py`](https://github.com/huggingface/transformers/blob/main/examples/pytorch/translation/run_translation_no_trainer.py)ã€‚

ä¸ `run_translation.py` ä¸€æ ·ï¼Œæ­¤è„šæœ¬å…è®¸æ‚¨åœ¨ç¿»è¯‘ä»»åŠ¡ä¸Šå¾®è°ƒä»»ä½•æ”¯æŒçš„æ¨¡å‹ï¼Œä¸»è¦åŒºåˆ«æ˜¯æ­¤è„šæœ¬æš´éœ²äº†åŸå§‹è®­ç»ƒå¾ªç¯ï¼Œå…è®¸æ‚¨å¿«é€Ÿå®éªŒå¹¶æ·»åŠ æ‚¨æƒ³è¦çš„ä»»ä½•è‡ªå®šä¹‰ã€‚

å®ƒæä¾›çš„é€‰é¡¹æ¯”ä½¿ç”¨ `Trainer` çš„è„šæœ¬å°‘ï¼ˆä¾‹å¦‚ï¼Œæ‚¨å¯ä»¥ç›´æ¥åœ¨è„šæœ¬ä¸­è½»æ¾æ›´æ”¹ä¼˜åŒ–å™¨æˆ–æ•°æ®åŠ è½½å™¨çš„é€‰é¡¹ï¼‰ï¼Œä½†ä»ç„¶åœ¨åˆ†å¸ƒå¼è®¾ç½®ä¸­è¿è¡Œï¼Œåœ¨ TPU ä¸Šè¿è¡Œï¼Œå¹¶é€šè¿‡ [ğŸ¤— `Accelerate`](https://github.com/huggingface/accelerate) åº“æ”¯æŒæ··åˆç²¾åº¦ã€‚å®‰è£…åï¼Œæ‚¨å¯ä»¥æ­£å¸¸ä½¿ç”¨è„šæœ¬ï¼š

```bash
pip install git+https://github.com/huggingface/accelerate
```

ç„¶å

```bash
python run_translation_no_trainer.py \
    --model_name_or_path Helsinki-NLP/opus-mt-en-ro \
    --source_lang en \
    --target_lang ro \
    --dataset_name wmt16 \
    --dataset_config_name ro-en \
    --output_dir ~/tmp/tst-translation
```

ç„¶åæ‚¨å¯ä»¥ä½¿ç”¨å¸¸ç”¨çš„å¯åŠ¨å™¨åœ¨åˆ†å¸ƒå¼ç¯å¢ƒä¸­è¿è¡Œå®ƒï¼Œä½†æœ€ç®€å•çš„æ–¹æ³•æ˜¯è¿è¡Œ

```bash
accelerate config
```

å¹¶å›ç­”æå‡ºçš„é—®é¢˜ã€‚ç„¶å

```bash
accelerate test
```

è¿™å°†æ£€æŸ¥è®­ç»ƒçš„ä¸€åˆ‡æ˜¯å¦å‡†å¤‡å°±ç»ªã€‚æœ€åï¼Œæ‚¨å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤å¯åŠ¨è®­ç»ƒï¼š

```bash
accelerate launch run_translation_no_trainer.py \
    --model_name_or_path Helsinki-NLP/opus-mt-en-ro \
    --source_lang en \
    --target_lang ro \
    --dataset_name wmt16 \
    --dataset_config_name ro-en \
    --output_dir ~/tmp/tst-translation
```

æ­¤å‘½ä»¤ç›¸åŒï¼Œå°†é€‚ç”¨äºï¼š

- ä»… CPU è®¾ç½®
- ä¸€ä¸ª GPU çš„è®¾ç½®
- å…·æœ‰å¤šä¸ª GPU çš„åˆ†å¸ƒå¼è®­ç»ƒï¼ˆå•èŠ‚ç‚¹æˆ–å¤šèŠ‚ç‚¹ï¼‰
- TPU ä¸Šçš„è®­ç»ƒ

è¯·æ³¨æ„ï¼Œæ­¤åº“å¤„äº alpha ç‰ˆæœ¬ï¼Œå› æ­¤å¦‚æœæ‚¨åœ¨ä½¿ç”¨å®ƒæ—¶é‡åˆ°ä»»ä½•é—®é¢˜ï¼Œæ‚¨çš„åé¦ˆéå¸¸æ¬¢è¿ã€‚
